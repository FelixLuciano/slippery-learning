{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozen Lake ‚õ∏Ô∏èüèûÔ∏è\n",
    "\n",
    "![](https://gymnasium.farama.org/_images/frozen_lake.gif)\n",
    "\n",
    "Este ambiente de treinamento envolve cruzar um lago congelado sem cair nos buracos congelantes. O agente deve aprender a evitar ir sempre na dire√ß√£o desejada por conta do gelo escorregadio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from lib.QLearning import QLearning\n",
    "from lib.Sarsa import Sarsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_4x4 = gym.make('FrozenLake-v1', map_name=\"4x4\", is_slippery=True).env\n",
    "env_8x8 = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=True).env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par√¢metros e Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_episodes = 30_000\n",
    "rolling_avg_window = int(n_of_episodes // 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram escolhidos dois casos para os hyperparametros para treinamento. O `hyperparameters_1` segue uma aprendizagem mais focada na Q-table com pouca aleatoriza√ß√£o e menos varia√ß√£o entre epis√≥dios. O `hyperparameters_2` tem uma aprendizagem mais aleatorizada por√©m busca utilizar mais a Q-table conforme os epis√≥dios, al√©m de dar mais √™nfaze no apendizado entre cada epis√≥dio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_1 = {\n",
    "    \"env\": env_4x4,\n",
    "    \"alpha\": 0.1,\n",
    "    \"gamma\": 0.99,\n",
    "    \"epsilon\": 0.1,\n",
    "    \"epsilon_min\": 0.1,\n",
    "    \"epsilon_dec\": 1,\n",
    "    \"episodes\": n_of_episodes,\n",
    "}\n",
    "\n",
    "hyperparameters_2 = {\n",
    "    \"env\": env_4x4,\n",
    "    \"alpha\": 0.25,\n",
    "    \"gamma\": 0.99,\n",
    "    \"epsilon\": 5.0,\n",
    "    \"epsilon_min\": 0.01,\n",
    "    \"epsilon_dec\": 0.99,\n",
    "    \"episodes\": n_of_episodes,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_qtable_1, q_learning_rewards_1, q_learning_actions_1 = QLearning(**hyperparameters_1).train()\n",
    "q_learning_qtable_2, q_learning_rewards_2, q_learning_actions_2 = QLearning(**hyperparameters_2).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa_qtable_1, sarsa_rewards_1, sarsa_actions_1 = Sarsa(**hyperparameters_1).train()\n",
    "sarsa_qtable_2, sarsa_rewards_2, sarsa_actions_2 = Sarsa(**hyperparameters_2).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lise de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_rewards_1[\"Rewards_avg\"] = q_learning_rewards_1[\"Rewards\"].rolling(window=rolling_avg_window).mean()\n",
    "q_learning_rewards_2[\"Rewards_avg\"] = q_learning_rewards_2[\"Rewards\"].rolling(window=rolling_avg_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa_rewards_1[\"Rewards_avg\"] = sarsa_rewards_1[\"Rewards\"].rolling(window=rolling_avg_window).mean()\n",
    "sarsa_rewards_2[\"Rewards_avg\"] = sarsa_rewards_2[\"Rewards\"].rolling(window=rolling_avg_window).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=q_learning_rewards_1[\"Episodes\"],\n",
    "        y=q_learning_rewards_1[\"Rewards_avg\"],\n",
    "        name=\"<br>Q-Learning<br>hyperparameters 1<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sarsa_rewards_1[\"Episodes\"],\n",
    "        y=sarsa_rewards_1[\"Rewards_avg\"],\n",
    "        name=\"<br>Sarsa<br>hyperparameters 1<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=q_learning_rewards_2[\"Episodes\"],\n",
    "        y=q_learning_rewards_2[\"Rewards_avg\"],\n",
    "        name=\"<br>Q-Learning<br>hyperparameters 2<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sarsa_rewards_2[\"Episodes\"],\n",
    "        y=sarsa_rewards_2[\"Rewards_avg\"],\n",
    "        name=\"<br>Sarsa<br>hyperparameters 2<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Compara√ß√£o entre Q-Learning e SARSA com diferentes hiperpar√¢metros\",\n",
    "    xaxis_title=\"Episodes\",\n",
    "    yaxis_title=\"Rewards\",\n",
    "    template=\"presentation\",\n",
    "    showlegend=True,\n",
    "    width=1_200,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro de sa√≠da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_learning_qtable_2.save_txt(\"results/best_q_learning.csv\")\n",
    "sarsa_qtable_2.savet_xt(\"results/best_sarsa.csv\")\n",
    "fig.write_image(\"results/Q-Learning_x_SARSA-hiperparametros.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 100\n",
    "n_tests_2 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      77.950000\n",
       "std        3.952687\n",
       "min       68.000000\n",
       "25%       75.000000\n",
       "50%       78.000000\n",
       "75%       81.000000\n",
       "max       91.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_q_learning = QLearning(**hyperparameters_2).load_txt(\"results/best_q_learning.csv\")\n",
    "\n",
    "tests_q_learning = []\n",
    "\n",
    "for _ in range(n_tests):\n",
    "    test_q_learning = pd.Series(\n",
    "        [\n",
    "            best_q_learning.test()\n",
    "            for _ in range(n_tests_2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    counts = test_q_learning.value_counts(normalize=True)\n",
    "    hits = counts[True] * 100\n",
    "\n",
    "    tests_q_learning.append(hits)\n",
    "\n",
    "tests_q_learning_describe = pd.Series(tests_q_learning).describe()\n",
    "tests_q_learning_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      82.860000\n",
       "std        3.967087\n",
       "min       72.000000\n",
       "25%       80.000000\n",
       "50%       83.000000\n",
       "75%       85.250000\n",
       "max       92.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sarsa = Sarsa(**hyperparameters_2).load_txt(\"results/best_sarsa.csv\")\n",
    "\n",
    "tests_sarsa = []\n",
    "\n",
    "for _ in range(n_tests):\n",
    "    test_sarsa = pd.Series(\n",
    "        [\n",
    "            best_sarsa.test()\n",
    "            for _ in range(n_tests_2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    counts = test_sarsa.value_counts(normalize=True)\n",
    "    hits = counts[True] * 100\n",
    "\n",
    "    tests_sarsa.append(hits)\n",
    "\n",
    "tests_sarsa_describe = pd.Series(tests_sarsa).describe()\n",
    "tests_sarsa_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "<br>Q-Learning<br>",
         "type": "histogram",
         "x": [
          82,
          80,
          74,
          78,
          82,
          81,
          76,
          80,
          77,
          74,
          80,
          77,
          71,
          81,
          82,
          83,
          76,
          79,
          76,
          73,
          77,
          79,
          72,
          76,
          77,
          75,
          91,
          75,
          74,
          77,
          80,
          79,
          86,
          77,
          83,
          74,
          75,
          74,
          81,
          73,
          83,
          78,
          81,
          78,
          81,
          78,
          75,
          82,
          73,
          75,
          79,
          78,
          69,
          80,
          82,
          77,
          72,
          80,
          73,
          73,
          78,
          78,
          79,
          78,
          74,
          82,
          76,
          81,
          80,
          80,
          70,
          75,
          81,
          82,
          78,
          77,
          79,
          82,
          77,
          82,
          72,
          80,
          79,
          80,
          84,
          79,
          81,
          80,
          73,
          84,
          77,
          68,
          86,
          81,
          69,
          78,
          78,
          80,
          78,
          75
         ],
         "xbins": {
          "end": 100,
          "size": 1,
          "start": 0
         }
        },
        {
         "name": "<br>Sarsa<br>",
         "type": "histogram",
         "x": [
          85,
          90,
          89,
          81,
          84,
          82,
          84,
          86,
          84,
          82,
          82,
          87,
          87,
          77,
          80,
          78,
          90,
          80,
          78,
          83,
          79,
          72,
          89,
          84,
          80,
          90,
          88,
          80,
          86,
          85,
          80,
          84,
          84,
          86,
          86,
          83,
          76,
          84,
          85,
          83,
          83,
          82,
          90,
          80,
          80,
          81,
          80,
          83,
          92,
          83,
          84,
          87,
          81,
          79,
          75,
          85,
          88,
          81,
          82,
          83,
          84,
          86,
          86,
          85,
          87,
          77,
          87,
          81,
          81,
          87,
          85,
          87,
          78,
          90,
          85,
          86,
          79,
          82,
          77,
          83,
          74,
          82,
          77,
          81,
          83,
          76,
          86,
          84,
          83,
          82,
          78,
          81,
          84,
          85,
          81,
          80,
          83,
          85,
          83,
          73
         ],
         "xbins": {
          "end": 100,
          "size": 1,
          "start": 0
         }
        }
       ],
       "layout": {
        "height": 700,
        "showlegend": true,
        "template": {
         "data": {
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scatter3d"
           }
          ],
          "scattergeo": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scattergl"
           }
          ],
          "scatterpolar": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "line": {
             "width": 3
            },
            "marker": {
             "size": 9
            },
            "type": "scatterternary"
           }
          ],
          "table": [
           {
            "cells": {
             "height": 30
            },
            "header": {
             "height": 36
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "font": {
           "size": 18
          },
          "xaxis": {
           "title": {
            "standoff": 15
           }
          },
          "yaxis": {
           "title": {
            "standoff": 15
           }
          }
         }
        },
        "title": {
         "text": "Distribui√ß√£o de acertos em 100 testes"
        },
        "width": 1200,
        "xaxis": {
         "title": {
          "text": "% Acertos em 100 epis√≥dios"
         }
        },
        "yaxis": {
         "title": {
          "text": "N√∫mero de ocorr√™ncias"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=tests_q_learning,\n",
    "        xbins=dict(\n",
    "            start=0,\n",
    "            end=100,\n",
    "            size=1,\n",
    "        ),\n",
    "        name=\"<br>Q-Learning<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=tests_sarsa,\n",
    "        xbins=dict(\n",
    "            start=0,\n",
    "            end=100,\n",
    "            size=1,\n",
    "        ),\n",
    "        name=\"<br>Sarsa<br>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Distribui√ß√£o de acertos em {n_tests} testes\",\n",
    "    xaxis_title=f\"% Acertos em {n_tests_2} epis√≥dios\",\n",
    "    yaxis_title=\"N√∫mero de ocorr√™ncias\",\n",
    "    template=\"presentation\",\n",
    "    showlegend=True,\n",
    "    width=1_200,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"results/Q-Learning_x_SARSA-tests.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto o agente Q-Learning como o Sarsa obtiveram um desempenho semelhante durante o treinamento e mostram resultados significativamente similares. No entanto, na etapa de testes, para 100 testes com 100 epis√≥dios cada, o Sara apresentou uma m√©dia de acertos por testes superior ao Q_Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
